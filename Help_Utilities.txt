个人税收递延型保险 95511 4001827726 gp02002029729014

保诚危急新产品

陆金所
ai9mdzno
5268550704470566

一个人一天可以看2000条或者听500条语料。


linux系统基本上分两大类：
1 RedHat系列：Redhat、Centos、Fedora等
2 Debian系列：Debian、Ubuntu等

RedHat系列：
1 常见的安装包格式 rpm 包，安装rpm包的命令是 “rpm -参数”
2 包管理工具 yum
3 支持tar包
Debian系列：
1 常见的安装包格式 deb 包，安装deb包的命令是 “dpkg -参数”
2 包管理工具 apt-get
3 支持tar包


linux下的find文件查找命令与grep文件内容查找命令
https://www.cnblogs.com/zhangmo/p/3571735.html
find / -name *.py -print
grep -nr --exclude-dir="testing" en_core_web_sm *
grep -R "en_core_web_sm " *|grep -v "\testing/*"


python面试题库
http://www.cnblogs.com/lmx123/p/9212079.html

如何在Python中一次读取N行文件？
https://cloud.tencent.com/developer/ask/32256


map是用同样方法把所有数据都改成别的，比如把列表的每个数都换成其平方。
reduce是用某种方法依次把所有数据丢进去最后得到一个结果，比如计算一个列表所有数的和的过程就是维持一个部分和然后依次把每个数加进去。
filter是筛选出其中满足某个条件的那些数据，比如挑出列表中所有非自然数。

>>> map(lambda x:x*x,[0,1,2,3,4,5,6])
[0, 1, 4, 9, 16, 25, 36]
>>> reduce(lambda x,y:x+y,[0,1,2,3,4,5,6])
>>> filter(lambda x:x&1,[0,1,2,3,4,5,6])
[1, 3, 5]

一行代码实现9*9乘法表
print ('\n'.join([' '.join(['%s*%s=%-2s' % (y,x,x*y) for y in range(1,x+1)]) for x in range(1,10)]))


Java如何配置环境变量
https://blog.csdn.net/sinat_36403828/article/details/78045618
https://blog.csdn.net/nextljp/article/details/77949597

Python如何配置环境变量
https://jingyan.baidu.com/article/3ea51489e1c2b752e61bbad0.html

tensorflow-GPU安装
https://blog.csdn.net/akon_wang_hkbu/article/details/78478513
https://blog.csdn.net/sb19931201/article/details/53648615
https://blog.csdn.net/ada_1215/article/details/72615245


git@github.com:howl-anderson/Chinese_models_for_SpaCy.git

Tasks < SemEval

THULAC：一个高效的中文词法分析工具包
https://github.com/ageron/handson-ml
https://github.com/Embedding/Chinese-Word-Vectors
https://github.com/buppt/ChineseNER
https://github.com/facebookresearch/fastText/blob/master/docs/crawl-vectors.md
https://github.com/thunlp/OpenKE
https://github.com/gunthercox/ChatterBot
https://github.com/explosion/spaCy
https://github.com/thunlp/THULAC-Python

清华大学开源软件镜像站
https://mirrors.tuna.tsinghua.edu.cn/help/anaconda/


python -m pip install -U pip
pip install --upgrade tensorflow-gpu
python -V
python -c "import os; path = os.sys.executable;folder=path[0 : path.rfind(os.sep)]; print (folder)"
python -c "import tensorflow; print (tensorflow.__version__)"
python -c "import spacy; print (spacy.__version__)"
python -c "import os; import spacy; print(os.path.dirname(spacy.__file__))"


sudo chown -R wangdi498:wangdi498 /home/wangdi498/anaconda3
anaconda3/envs/rasa/lib/python3.6/site-packages/spacy-2.0.12.dist-info/METADATA
anaconda3/envs/rasa/lib/python3.6/site-packages/en_core_web_sm-2.0.0-py3.6.egg-info

conda服务器在国外，速度非常慢，需要加入国内清华的镜像。
conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/



智能投研
深度发掘金融市场的非结构化信息（如文本信息），构建与现有数据系统不同的基于自然语言的金融平台，为投资者的信息搜集，抽取，分析提供全新的解决方案。

个性化金融信息推荐
实时监测全球金融动态，利用自然语言处理技术和深度学习全面整合最新资讯，为投资者个性化定向抽取最相关信息，把握稍纵即逝的交易时机。

智能大数据
提供基于新闻事件，公司公告，政府信息公示，行业法规政策等信息整合的金融大数据库，利用机器学习算法与传统数据深度整合，开拓新的应用场景和投资机会。



好好学习天天向上：

差异化经营

最小可用

桑基图(Sankey)

Neo4J

NGinx

Restful API

tree-based LSTM

zhusuan

对于没有意向的用户采取挽回话术；对于无法判断意向的用户采取兜底话术。

知识库解决有没有；算法解决精不精。

人口属性、消费习惯、地理、行业、应用兴趣。

三升一降：提升业绩、效率、体验，降低成本。

假设有10个物体，那么RCNN做10次，fastRCNN做1次，fasterRCNN做0次。目标函数有5个loss：smooth+inos。

KS、PSI、Lawerance Curve、X2分割、IV值、皮尔森相关系数（Pearson correlation coefficient）。可以用Bayesian Optimization来调hyper-parameter。

时间序列如果用GRU来做会有overfitting，所以用XGBoost/LightGBM做树。特征是日期、交易额度、单数等等，叶结点是预测的钱数，残差是RMSE。每条路径都对应一个钱数，
每次训练就是走一次路径，把训练数据得到的钱数相加取平均。宁可要较大但是可控的RMSE、也不要偶尔非常outlier的RMSE。

阅读理解 vs 表示学习，mutual vector
soft match vs exact match
Skill vs Intent
技术roadmap vs 功能roadmap



逻辑斯谛回归与最大熵模型
http://www.hankcs.com/ml/the-logistic-regression-and-the-maximum-entropy-model.html#h3-6

语言模型评价指标Perplexity
https://blog.csdn.net/index20001/article/details/78884646

深入研究NLU和DM
http://baijiahao.baidu.com/s?id=1601539772415682443&wfr=spider&for=pc

如何打造主动式对话机器人
https://www.sohu.com/a/231794637_610300

N-gram
https://blog.csdn.net/songbinxu/article/details/80209197

中文分词
https://blog.csdn.net/liujianfei526/article/details/50640176
https://blog.csdn.net/u012558945/article/details/79918771
https://www.cnblogs.com/echo-cheng/p/7967221.html
https://blog.csdn.net/rav009/article/details/12196623

中文分词深度学习（字嵌入+Bi-LSTM+CRF）
https://blog.csdn.net/chivalrousli/article/details/70482488

这里给出上面算法和word2vec源码中的变量对应关系
https://www.cnblogs.com/pinard/p/7249903.html
https://github.com/tmikolov/word2vec/blob/master/word2vec.c
在源代码中，基于Negative Sampling的CBOW模型算法在464-494行，基于Hierarchical Softmax的Skip-Gram的模型算法在520-542行。
在源代码中，neule对应我们上面的e, syn0对应我们的xw, syn1neg对应我们的θwi, layer1_size对应词向量的维度，window对应我们的c。negative对应我们的neg, table_size对应我们负采样中的划分数M。
另外，vocab[word].code[d]指的是，当前单词word的，第d个编码，编码不含Root结点。vocab[word].point[d]指的是，当前单词word，第d个编码下，前置的结点。这些和基于Hierarchical Softmax的是一样的。

计算分词权重
http://f.dataguru.cn/thread-882078-1-1.html
https://www.cnblogs.com/clover-siyecao/p/5726480.html
https://blog.csdn.net/kl28978113/article/details/54580838

word2vec中的数学原理详解
https://blog.csdn.net/itplus/article/details/37969635

word2vec原理
http://www.cnblogs.com/pinard/p/7160330.html
http://www.hankcs.com/nlp/word2vec.html

用gensim学习word2vec
https://www.cnblogs.com/pinard/p/7278324.html

词向量经典模型：从word2vec、glove、ELMo到BERT
https://blog.csdn.net/xiayto/article/details/84730009
https://blog.csdn.net/weixin_37947156/article/details/83146141
https://x-algo.cn/index.php/2018/11/12/3083/


基于神经网络的高性能依存句法分析器
http://www.hankcs.com/nlp/parsing/neural-network-based-dependency-parser.html

文本主题模型LDA
LDA预设若干主题。每篇文章有两部分：1若干个主图，2每个主题有不同的词汇分布。
http://www.cnblogs.com/pinard/p/6831308.html
http://www.cnblogs.com/pinard/p/6908150.html
https://blog.csdn.net/FlySky1991/article/details/77623549

文本分类主题预测FastText、TextCNN、TextRNN、TextRCNN等等综述
https://blog.csdn.net/qq_25439417/article/details/82529312

关键词摘要：基于pagerank实现的textrank和textteaser
句子重要性的特征向量 = [位置，关键词，标题]
https://blog.csdn.net/qq_14950717/article/details/78987342
https://blog.csdn.net/Silience_Probe/article/details/80700018

注意力机制
https://blog.csdn.net/tg229dvt5i93mxaq5a6u/article/details/78422216

